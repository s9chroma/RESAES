{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Link: https://arxiv.org/abs/2003.04696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchio\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.distributions as dist\n",
    "import math\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = r\"W:\\12cp\\data\\mood.h5\"\n",
    "validation_data = r\"W:\\12cp\\data\\MOOD_toytest_brain.h5\"\n",
    "log_path = r\"W:\\12cp\\log\"\n",
    "save_path = r\"W:\\12cp\\save_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_workers=0\n",
    "trainID=\"RESAES\"\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preload_h5 = True\n",
    "indicesOfImgVols = [1,2] #Supply list of indices if only a subset is desired\n",
    "patch_size=(256,256,1) #Set it to None if not desired\n",
    "patchQ_len = 512\n",
    "patches_per_volume = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_val=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(256,256,256)\n",
    "encode_features=128\n",
    "linear_op = True\n",
    "normalize=True\n",
    "if_rsr=True\n",
    "enforce_proj=True\n",
    "all_alt=False\n",
    "lambda1 = 0.1\n",
    "lambda2 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_region='brain'\n",
    "useCuda=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Data.ipynb\n"
     ]
    }
   ],
   "source": [
    "from Data import MoodTrainSet, MoodValSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading MoodTrainSet\n",
      "Preloading MoodValSet\n"
     ]
    }
   ],
   "source": [
    "trainset = MoodTrainSet(indices=indicesOfImgVols, region=mood_region, data_path=training_data, lazypatch=True if patch_size else False, preload=preload_h5)\n",
    "valset = MoodValSet(data_path=validation_data, lazypatch=True if patch_size else False, preload=preload_h5)\n",
    "\n",
    "if patch_size:\n",
    "  input_shape = tuple(x for x in patch_size if x!=1)\n",
    "  trainset = torchio.data.Queue(\n",
    "                  subjects_dataset = trainset,\n",
    "                  max_length = patchQ_len,\n",
    "                  samples_per_volume = patches_per_volume,\n",
    "                  sampler = torchio.data.UniformSampler(patch_size=patch_size),\n",
    "                  # num_workers = num_workers\n",
    "                  )\n",
    "  valset = torchio.data.Queue(\n",
    "                  subjects_dataset = valset,\n",
    "                  max_length = patchQ_len,\n",
    "                  samples_per_volume = patches_per_volume,\n",
    "                  sampler = torchio.data.UniformSampler(patch_size=patch_size),\n",
    "                  # num_workers = num_workers\n",
    "                  )\n",
    "\n",
    "train_loader = DataLoader(dataset=trainset,batch_size=batch_size,shuffle=False, num_workers=num_workers)\n",
    "val_loader = None if (valset is None) or (not do_val) else DataLoader(dataset=valset,batch_size=batch_size,shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_channels, output_channels, kernel_size, stride):\n",
    "  return nn.Sequential(nn.Conv2d(input_channels, output_channels, kernel_size, stride, bias=False),\n",
    "                    nn.BatchNorm2d(output_channels),\n",
    "                    nn.LeakyReLU(0.2, inplace=True))\n",
    "  \n",
    "def linear_enc(input_channels, output_channels):\n",
    "  return nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_channels, out_features=output_channels),\n",
    "      nn.BatchNorm1d(num_features=output_channels),\n",
    "      nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, no_channels, filter_size, latent_size, linear_op=True):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.linear_op = linear_op\n",
    "        self.conv1 = conv_block(no_channels, filter_size, kernel_size=5, stride=2)\n",
    "        self.conv2 = conv_block(filter_size, filter_size*2, kernel_size=5, stride=2)\n",
    "        self.conv3 = conv_block(filter_size*2, filter_size*4, kernel_size=5, stride=2)\n",
    "        self.linear = linear_enc(29*29*filter_size*4, latent_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        if self.linear_op:\n",
    "          x_rsr = self.linear(x)\n",
    "        return x, x_rsr\n",
    "\n",
    "def deconv(input_channels, output_channels, kernel_size, stride):\n",
    "  return nn.Sequential(nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, bias=False),\n",
    "                    nn.BatchNorm2d(output_channels),\n",
    "                    nn.LeakyReLU(0.2, inplace=True))\n",
    "  \n",
    "def linear_dec(input_channels, output_channels):\n",
    "  return nn.Sequential(\n",
    "      nn.Linear(in_features=input_channels, out_features=output_channels),\n",
    "      nn.BatchNorm1d(num_features=output_channels),\n",
    "      nn.LeakyReLU(0.2, inplace=True),\n",
    "      Unflatten((128,29,29)))\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Unflatten, self).__init__()\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input.view(len(input), self.shape[0], self.shape[1], self.shape[2])\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, no_channels, filter_size, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.linear = linear_dec(latent_size, 29*29*filter_size*4)\n",
    "        self.deconv1 = deconv(filter_size*4, filter_size*2, 6, 2)\n",
    "        self.deconv2 = deconv(filter_size*2, filter_size, 5, 2)\n",
    "        self.deconv3 = deconv(filter_size, no_channels, 4, 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.linear(input)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aes(nn.Module):\n",
    "    def __init__(self, no_channels, filter_size, latent_size, normalize=True, linear_op=True):\n",
    "        super(Aes, self).__init__()\n",
    "        self.Encoder = Encoder(no_channels=no_channels, filter_size=filter_size, latent_size=latent_size, linear_op=linear_op)\n",
    "        self.Decoder = Decoder(no_channels=no_channels, filter_size=filter_size, latent_size=latent_size)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, input):\n",
    "        y, y_rsr = self.Encoder(input)\n",
    "        if self.normalize:\n",
    "          z = f.normalize(y_rsr, dim=-1, p=2)\n",
    "        else:\n",
    "          z = y_rsr\n",
    "        x_tilde = self.Decoder(z)\n",
    "        return y, y_rsr, z, x_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_error(x, xtilde):\n",
    "  return torch.mean(torch.norm(x-x_tilde, dim=1))\n",
    "\n",
    "def pca_error(y, z):\n",
    "  y = y.reshape(y.shape[0],-1)\n",
    "  A = Variable(torch.randn(y.shape[-1], 128))\n",
    "  z = torch.matmul(z, torch.transpose(A,0,1))\n",
    "  return torch.mean(torch.norm(y-z, dim=1)) # it's 2 or 'fro' by default\n",
    "\n",
    "def proj_error(y, z):\n",
    "  y = y.reshape(y.shape[0],-1)\n",
    "  A = Variable(torch.randn(y.shape[-1], 128))\n",
    "  z = torch.matmul(z, torch.transpose(A,0,1))\n",
    "  return torch.mean(torch.square(torch.matmul(torch.transpose(A,0,1), A) - torch.eye(128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and useCuda else \"cpu\")\n",
    "tb_writer = SummaryWriter(log_dir = os.path.join(log_path,trainID))\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "logname = os.path.join(save_path, 'log_'+trainID+'.txt')\n",
    "logging.basicConfig(filename=logname,\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint2load = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Aes(no_channels=1, filter_size=32, latent_size=128, normalize=normalize, linear_op=linear_op)\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer2 = Adam(model.parameters(), lr=10*learning_rate)\n",
    "optimizer3 = Adam(model.parameters(), lr=10*learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_rec = nn.MSELoss()\n",
    "runningLoss = 0.0\n",
    "runningLossCounter = 0.0\n",
    "train_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint2load:\n",
    "    chk = torch.load(checkpoint2load)\n",
    "    model.load_state_dict(chk['state_dict'])\n",
    "    optimizer.load_state_dict(chk['optimizer'])\n",
    "    amp.load_state_dict(chk['amp'])\n",
    "    start_epoch = chk['epoch'] + 1\n",
    "    best_loss = chk['loss'] \n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                  | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 256/256 [00:14<00:00, 17.46it/s]\n",
      "  3%|▌                       | 13/512 [00:00<00:04, 119.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 512/512 [00:28<00:00, 17.68it/s]\n",
      "  0%|                                  | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 256/256 [00:14<00:00, 18.27it/s]\n",
      "  3%|▌                       | 13/512 [00:00<00:03, 126.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 512/512 [00:28<00:00, 17.99it/s]\n",
      "  0%|                                  | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                  | 0/256 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-f7d4b2643445>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torchio\\data\\queue.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Patches list is empty.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0msample_patch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_sampled_patches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torchio\\data\\queue.py\u001b[0m in \u001b[0;36mfill\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0msubject_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_subject_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0miterable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mpatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples_per_volume\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle_patches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torchio\\data\\sampler\\weighted.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, sample, num_patches)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mpatches_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_patches\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnum_patches\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mpatches_left\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_patch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_patches\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mpatches_left\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torchio\\data\\sampler\\weighted.py\u001b[0m in \u001b[0;36mextract_patch\u001b[1;34m(self, sample, probability_map, cdf, sort_indices)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0msort_indices\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m             ) -> Subject:\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mindex_ini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_index_ini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobability_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mindex_fin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_ini\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0mcropped_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_ini\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_fin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torchio\\data\\sampler\\weighted.py\u001b[0m in \u001b[0;36mget_random_index_ini\u001b[1;34m(self, probability_map, cdf, sort_indices)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0msort_indices\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             ) -> np.ndarray:\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mcenter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_probability_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobability_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;31m# See self.clear_probability_borders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torchio\\data\\sampler\\weighted.py\u001b[0m in \u001b[0;36msample_probability_map\u001b[1;34m(self, probability_map, cdf, sort_indices)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mcdf_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# proceed as usual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[0mcdf_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_number\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mcdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mrandom_location_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msort_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcdf_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train().to(device)\n",
    "    runningLoss = 0.0\n",
    "    runningLossCounter = 0.0\n",
    "    train_loss = 0.0\n",
    "    print('Epoch '+ str(epoch)+ ': Training')\n",
    "    \n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for i, data in enumerate(train_loader):\n",
    "            try:\n",
    "                img = data['img']['data'].squeeze(-1)\n",
    "                data = Variable(img).to(device)\n",
    "                model.zero_grad()\n",
    "                y, y_rsr, z, x_tilde=model(data)\n",
    "                    \n",
    "                if if_rsr and not all_alt:\n",
    "                    loss = recon_error(data, x_tilde) + lambda1 * pca_error(y, y_rsr) + lambda2 * proj_error(y, y_rsr)\n",
    "                else:\n",
    "                    loss = recon_error(data, x_tilde)\n",
    "                    \n",
    "                if not torch.isfinite(loss):\n",
    "                    logging.error('Loss is not finite. Skipping the iteration.')\n",
    "                    continue\n",
    "                    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if enforce_proj and all_alt:\n",
    "                    loss_proj = proj_error(y, y_rsr)\n",
    "                    loss_proj.backward()\n",
    "                    optimizer2.step()\n",
    "                if all_alt:\n",
    "                    loss_alt = pca_error(y, y_rsr)\n",
    "                    loss_alt.backward()\n",
    "                    optimizer3.step()\n",
    "                print(loss)\n",
    "                loss = round(loss.item(),4)\n",
    "                train_loss += loss\n",
    "                runningLoss += loss\n",
    "                runningLossCounter += 1\n",
    "                logging.info('[%d/%d][%d/%d] Train Loss: %.4f' % ((epoch+1), num_epochs, i, len(train_loader), loss))\n",
    "                    \n",
    "                if i % log_freq == 0:\n",
    "                    niter = epoch*len(train_loader)+i\n",
    "                    tb_writer.add_scalar('Train/Loss', runningLoss/runningLossCounter, niter)\n",
    "                    runningLoss = 0.0\n",
    "                    runningLossCounter = 0.0\n",
    "            except Exception as e:\n",
    "                logging.error(str(e))\n",
    "                pbar.update(1)\n",
    "    checkpoint = {\n",
    "      'model': model,\n",
    "      'state_dict': model.state_dict(),\n",
    "      'optimizer': optimizer.state_dict()\n",
    "      #'amp': amp.state_dict()\n",
    "      }\n",
    "    \n",
    "    torch.save(checkpoint, os.path.join(save_path, trainID+\".pth.tar\"))\n",
    "    tb_writer.add_scalar('Train/AvgLossEpoch', train_loss/len(train_loader), epoch)\n",
    "    \n",
    "    if val_loader:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print('Epoch '+ str(epoch)+ ': Validation')\n",
    "            with tqdm(total=len(val_loader)) as pbar:\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    try:\n",
    "                        img = data['img']['data'].squeeze(-1)\n",
    "                        images = Variable(img).to(device)\n",
    "                        y, y_rsr, z, x_tilde = model(images)\n",
    "                        loss_rec = recon_error(data, x_tilde)\n",
    "                        loss_pca = pca_error(y, y_rsr)\n",
    "                        loss_proj = proj_error(y, y_rsr)\n",
    "                        loss = loss_rec + loss_pca + loss_proj\n",
    "                        logging.info('[%d/%d][%d/%d] Val Loss: %.4f' % ((epoch+1), num_epochs, i, len(val_loader), loss.mean().item()))\n",
    "                        niter = epoch*len(val_loader)+i\n",
    "                        for j in range(images.size(0)):\n",
    "                            tb_writer.add_scalar('Val/Loss', loss[j].item(), (batch_size*niter)+j)\n",
    "                            tb_writer.add_scalar('Val/GT', y[j], (batch_size*niter)+j)\n",
    "                    except Exception as ex:\n",
    "                        logging.error(ex)\n",
    "                    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
