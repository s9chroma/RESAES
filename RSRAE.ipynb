{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use TorchIO for your research, please cite the following paper:\n",
      "Pérez-García et al., TorchIO: a Python library for efficient loading,\n",
      "preprocessing, augmentation and patch-based sampling of medical images\n",
      "in deep learning. Link: https://arxiv.org/abs/2003.04696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchio\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.distributions as dist\n",
    "import math\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = r\"W:\\12cp\\data\\mood.h5\"\n",
    "validation_data = r\"W:\\12cp\\data\\MOOD_toytest_brain.h5\"\n",
    "log_path = r\"W:\\12cp\\log\"\n",
    "save_path = r\"W:\\12cp\\save_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.set_device(0)\n",
    "batch_size = 128\n",
    "num_workers=0\n",
    "trainID=\"RESAES\"\n",
    "learning_rate = 0.00025\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preload_h5 = True\n",
    "indicesOfImgVols = [1,2] #Supply list of indices if only a subset is desired\n",
    "patch_size=(256,256,1) #Set it to None if not desired\n",
    "patchQ_len = 512\n",
    "patches_per_volume = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_val=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(256,256,256)\n",
    "encode_features=128\n",
    "linear_op = True\n",
    "normalize=True\n",
    "if_rsr=True\n",
    "enforce_proj=True\n",
    "all_alt=False\n",
    "lambda1 = 0.1\n",
    "lambda2 = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_region='brain'\n",
    "useCuda=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Data.ipynb\n"
     ]
    }
   ],
   "source": [
    "from Data import MoodTrainSet, MoodValSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading MoodTrainSet\n",
      "Preloading MoodValSet\n"
     ]
    }
   ],
   "source": [
    "trainset = MoodTrainSet(indices=indicesOfImgVols, region=mood_region, data_path=training_data, lazypatch=True if patch_size else False, preload=preload_h5)\n",
    "valset = MoodValSet(data_path=validation_data, lazypatch=True if patch_size else False, preload=preload_h5)\n",
    "\n",
    "if patch_size:\n",
    "  input_shape = tuple(x for x in patch_size if x!=1)\n",
    "  trainset = torchio.data.Queue(\n",
    "                  subjects_dataset = trainset,\n",
    "                  max_length = patchQ_len,\n",
    "                  samples_per_volume = patches_per_volume,\n",
    "                  sampler = torchio.data.UniformSampler(patch_size=patch_size),\n",
    "                  # num_workers = num_workers\n",
    "                  )\n",
    "  valset = torchio.data.Queue(\n",
    "                  subjects_dataset = valset,\n",
    "                  max_length = patchQ_len,\n",
    "                  samples_per_volume = patches_per_volume,\n",
    "                  sampler = torchio.data.UniformSampler(patch_size=patch_size),\n",
    "                  # num_workers = num_workers\n",
    "                  )\n",
    "\n",
    "train_loader = DataLoader(dataset=trainset,batch_size=batch_size,shuffle=False, num_workers=num_workers)\n",
    "val_loader = None if (valset is None) or (not do_val) else DataLoader(dataset=valset,batch_size=batch_size,shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_channels, output_channels, kernel_size, stride):\n",
    "  return nn.Sequential(nn.Conv2d(input_channels, output_channels, kernel_size, stride, bias=False),\n",
    "                    nn.BatchNorm2d(output_channels),\n",
    "                    nn.LeakyReLU(0.2, inplace=True))\n",
    "  \n",
    "def linear_enc(input_channels, output_channels):\n",
    "  return nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_channels, out_features=output_channels),\n",
    "      nn.BatchNorm1d(num_features=output_channels),\n",
    "      nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, no_channels, filter_size, latent_size, linear_op=True):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.linear_op = linear_op\n",
    "        self.conv1 = conv_block(no_channels, filter_size, kernel_size=5, stride=2)\n",
    "        self.conv2 = conv_block(filter_size, filter_size*2, kernel_size=5, stride=2)\n",
    "        self.conv3 = conv_block(filter_size*2, filter_size*4, kernel_size=5, stride=2)\n",
    "        self.linear = linear_enc(29*29*filter_size*4, latent_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        if self.linear_op:\n",
    "          x_rsr = self.linear(x)\n",
    "        return x, x_rsr\n",
    "\n",
    "def deconv(input_channels, output_channels, kernel_size, stride):\n",
    "  return nn.Sequential(nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, bias=False),\n",
    "                    nn.BatchNorm2d(output_channels),\n",
    "                    nn.LeakyReLU(0.2, inplace=True))\n",
    "  \n",
    "def linear_dec(input_channels, output_channels):\n",
    "  return nn.Sequential(\n",
    "      nn.Linear(in_features=input_channels, out_features=output_channels),\n",
    "      nn.BatchNorm1d(num_features=output_channels),\n",
    "      nn.LeakyReLU(0.2, inplace=True),\n",
    "      Unflatten((128,29,29)))\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Unflatten, self).__init__()\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input.view(len(input), self.shape[0], self.shape[1], self.shape[2])\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, no_channels, filter_size, latent_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.linear = linear_dec(latent_size, 29*29*filter_size*4)\n",
    "        self.deconv1 = deconv(filter_size*4, filter_size*2, 6, 2)\n",
    "        self.deconv2 = deconv(filter_size*2, filter_size, 5, 2)\n",
    "        self.deconv3 = deconv(filter_size, no_channels, 4, 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.linear(input)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.deconv2(x)\n",
    "        x = self.deconv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aes(nn.Module):\n",
    "    def __init__(self, no_channels, filter_size, latent_size, normalize=True, linear_op=True):\n",
    "        super(Aes, self).__init__()\n",
    "        self.Encoder = Encoder(no_channels=no_channels, filter_size=filter_size, latent_size=latent_size, linear_op=linear_op)\n",
    "        self.Decoder = Decoder(no_channels=no_channels, filter_size=filter_size, latent_size=latent_size)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def forward(self, input):\n",
    "        y, y_rsr = self.Encoder(input)\n",
    "        if self.normalize:\n",
    "          z = f.normalize(y_rsr, dim=-1, p=2)\n",
    "        else:\n",
    "          z = y_rsr\n",
    "        x_tilde = self.Decoder(z)\n",
    "        return y, y_rsr, z, x_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_error(x, xtilde):\n",
    "  return torch.mean(torch.norm(xtilde, dim=1))\n",
    "\n",
    "def pca_error(y, z):\n",
    "    y = y.reshape(y.shape[0],-1)\n",
    "    A = Variable(torch.randn(y.shape[-1], 128))\n",
    "    z = torch.matmul(z, torch.transpose(A,0,1))\n",
    "    return torch.mean(torch.norm(y-z, dim=1)) # it's 2 or 'fro' by default\n",
    "\n",
    "def proj_error(y):\n",
    "    A = Variable(torch.randn(y.shape[-1], 128))\n",
    "    \n",
    "    return torch.mean(torch.square(torch.matmul(torch.transpose(A,0,1), A) - torch.eye(128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_freq = 10\n",
    "tb_writer = SummaryWriter(log_dir = os.path.join(log_path,trainID))\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "logname = os.path.join(save_path, 'log_'+trainID+'.txt')\n",
    "logging.basicConfig(filename=logname,\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint2load = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Aes(no_channels=1, filter_size=32, latent_size=128, normalize=normalize, linear_op=linear_op)\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer2 = Adam(model.parameters(), lr=10*learning_rate)\n",
    "optimizer3 = Adam(model.parameters(), lr=10*learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_rec = nn.MSELoss()\n",
    "runningLoss = 0.0\n",
    "runningLossCounter = 0.0\n",
    "train_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if checkpoint2load:\n",
    "    chk = torch.load(checkpoint2load)\n",
    "    model.load_state_dict(chk['state_dict'])\n",
    "    optimizer.load_state_dict(chk['optimizer'])\n",
    "    amp.load_state_dict(chk['amp'])\n",
    "    start_epoch = chk['epoch'] + 1\n",
    "    best_loss = chk['loss'] \n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                    | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████                     | 1/4 [00:08<00:26,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  172.3869 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████              | 2/4 [00:18<00:17,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  169.74 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████       | 3/4 [00:40<00:12, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  167.4828 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 4/4 [00:49<00:00, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  167.592 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                    | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███▌                        | 1/8 [00:03<00:27,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(2568.5210) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████                     | 2/8 [00:08<00:24,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(2622.0723) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████▌                 | 3/8 [00:25<00:39,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(2619.4324) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████              | 4/8 [00:28<00:26,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(2647.5857) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████▌          | 5/8 [00:32<00:17,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(2583.4878) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████▌          | 5/8 [00:33<00:20,  6.71s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-220ec4c3ab14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_rsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tilde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                     \u001b[0mloss_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecon_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tilde\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                     \u001b[0mloss_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_rsr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-3c5728f3ed95>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_rsr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m           \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_rsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-bc1ac5748bb0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_op\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1291\u001b[0m                 inplace=inplace)\n\u001b[0;32m   1292\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1293\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1294\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train().to(device)\n",
    "    runningLoss = 0.0\n",
    "    runningLossCounter = 0.0\n",
    "    train_loss = 0.0\n",
    "    print('Epoch '+ str(epoch)+ ': Training')\n",
    "    \n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for i, data in enumerate(train_loader):\n",
    "            img = data['img']['data'].squeeze(-1)\n",
    "            data = Variable(img).to(device)\n",
    "            model.zero_grad()\n",
    "            y, y_rsr, z, x_tilde=model(data)\n",
    "            if if_rsr and not all_alt:\n",
    "                loss = recon_error(data, x_tilde) + lambda1 * pca_error(y, y_rsr) + lambda2 * proj_error(y)\n",
    "            else:\n",
    "                loss = recon_error(data, x_tilde)\n",
    "            if not torch.isfinite(loss):\n",
    "                logging.error('Loss is not finite. Skipping the iteration.')\n",
    "                continue\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if enforce_proj and all_alt:\n",
    "                loss_proj = proj_error(y, y_rsr)\n",
    "                loss_proj.backward()\n",
    "                optimizer2.step()\n",
    "            if all_alt:\n",
    "                loss_alt = pca_error(y, y_rsr)\n",
    "                loss_alt.backward()\n",
    "                optimizer3.step()\n",
    "            loss = round(loss.item(),4)\n",
    "            #print(\"Training Loss: \", loss, \"\\n\")\n",
    "            train_loss += loss\n",
    "            runningLoss += loss\n",
    "            runningLossCounter += 1\n",
    "            logging.info('[%d/%d][%d/%d] Train Loss: %.4f' % ((epoch+1), num_epochs, i, len(train_loader), loss))\n",
    "            if i % log_freq == 0:\n",
    "                niter = epoch*len(train_loader)+i\n",
    "                tb_writer.add_scalar('Train/Loss', runningLoss/runningLossCounter, niter)\n",
    "                runningLoss = 0.0\n",
    "                runningLossCounter = 0.0\n",
    "\n",
    "            pbar.update(1)\n",
    "    checkpoint = {\n",
    "      'model': model,\n",
    "      'state_dict': model.state_dict(),\n",
    "      'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, os.path.join(save_path, trainID+\".pth.tar\"))\n",
    "    tb_writer.add_scalar('Train/AvgLossEpoch', train_loss/len(train_loader), epoch)\n",
    "    \n",
    "    if val_loader:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print('Epoch '+ str(epoch)+ ': Validation')\n",
    "            with tqdm(total=len(val_loader)) as pbar:\n",
    "                for i, data in enumerate(val_loader):\n",
    "                    img = data['img']['data'].squeeze(-1)\n",
    "                    images = Variable(img).to(device)\n",
    "                    y, y_rsr, z, x_tilde = model(images)\n",
    "                    loss_rec = recon_error(data, x_tilde)\n",
    "                    loss_pca = pca_error(y, y_rsr)\n",
    "                    loss_proj = proj_error(y)\n",
    "                    loss = loss_rec + loss_pca + loss_proj\n",
    "                    #print(\"Validation Loss: \", loss, \"\\n\")\n",
    "                    logging.info('[%d/%d][%d/%d] Val Loss: %.4f' % ((epoch+1), num_epochs, i, len(val_loader), loss.mean().item()))\n",
    "                    niter = epoch*len(val_loader)+i\n",
    "                    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
