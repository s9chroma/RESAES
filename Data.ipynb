{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "id": "WQLig-6w3S4j",
    "outputId": "1f488077-68fa-4cf2-e355-4d38c4fa2d7c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import nibabel as nib\n",
    "\n",
    "from torchio.data.image import Image\n",
    "import torchio\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchio.data.subject import Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "s8avp4aO2Gum"
   },
   "outputs": [],
   "source": [
    "class H5DSImage(Image):\n",
    "    def __init__(self, h5DS=None, lazypatch=True, imtype=torchio.INTENSITY, **kwargs):\n",
    "        kwargs['path'] = ''\n",
    "        kwargs['type'] = imtype\n",
    "        super().__init__(**kwargs)\n",
    "        self.h5DS = h5DS\n",
    "        self.lazypatch = lazypatch\n",
    "        if not self.lazypatch:\n",
    "            self.load()\n",
    "\n",
    "    def load(self) -> None:\n",
    "        if self._loaded:\n",
    "            return\n",
    "        if self.lazypatch:\n",
    "            tensor, affine = self.h5DS, np.eye(4)\n",
    "        else:\n",
    "            tensor, affine = self.read_and_check_h5(self.h5DS)\n",
    "        self[torchio.DATA] = tensor\n",
    "        self[torchio.AFFINE] = affine\n",
    "        self._loaded = True\n",
    "\n",
    "    @property\n",
    "    def spatial_shape(self):\n",
    "        if self.lazypatch:\n",
    "            return self.shape\n",
    "        else:\n",
    "            return self.shape[1:]\n",
    "\n",
    "    def crop(self, index_ini, index_fin):\n",
    "        new_origin = nib.affines.apply_affine(self.affine, index_ini)\n",
    "        new_affine = self.affine.copy()\n",
    "        new_affine[:3, 3] = new_origin\n",
    "        i0, j0, k0 = index_ini\n",
    "        i1, j1, k1 = index_fin\n",
    "        if len(self.data.shape) == 4:\n",
    "            patch = self.data[:, i0:i1, j0:j1, k0:k1]\n",
    "        else:\n",
    "            patch = np.expand_dims(self.data[i0:i1, j0:j1, k0:k1], 0)\n",
    "        if not isinstance(self.data, torch.Tensor):\n",
    "            patch = torch.from_numpy(patch)\n",
    "        kwargs = dict(\n",
    "            tensor=patch,\n",
    "            affine=new_affine,\n",
    "            type=self.type,\n",
    "            path=self.path,\n",
    "            h5DS=self.h5DS\n",
    "        )\n",
    "        for key, value in self.items():\n",
    "            if key in torchio.data.image.PROTECTED_KEYS: continue\n",
    "            kwargs[key] = value  \n",
    "        return self.__class__(**kwargs)\n",
    "\n",
    "    def read_and_check_h5(self, h5DS):\n",
    "        tensor, affine = torch.from_numpy(h5DS[()]).unsqueeze(0), np.eye(4)\n",
    "        tensor = super().parse_tensor_shape(tensor)\n",
    "        if self.channels_last:\n",
    "            tensor = tensor.permute(3, 0, 1, 2)\n",
    "        if self.check_nans and torch.isnan(tensor).any():\n",
    "            warnings.warn(f'NaNs found in file \"{path}\"')\n",
    "        return tensor, affine\n",
    "\n",
    "\n",
    "class MoodTrainSet(Dataset):\n",
    "    def __init__(self, indices=None, region='brain', data_path='MOOD_train.h5', torchiosub=True, lazypatch=True, preload=False):\n",
    "        self.h5 = h5.File(data_path, 'r', swmr=True)\n",
    "        self.samples = []\n",
    "        if indices:\n",
    "            self.samples = [self.h5[region][str(i).zfill(5)]for i in indices]\n",
    "            # self.samples2 = [self.h5[region][str(i).zfill(5)][:] for i in indices]\n",
    "        else:\n",
    "            self.samples = [self.h5[region][i] for i in list(self.h5[region])]\n",
    "        if preload:\n",
    "            print('Preloading MoodTrainSet')\n",
    "            for i in range(len(self.samples)):\n",
    "                self.samples[i] = self.samples[i][:]\n",
    "        self.torchiosub = torchiosub\n",
    "        self.lazypatch = lazypatch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.torchiosub:\n",
    "            return Subject({'img':H5DSImage(self.samples[item], lazypatch=self.lazypatch)})\n",
    "        else:\n",
    "            return torch.from_numpy(self.samples[item][()]).unsqueeze(0)\n",
    "\n",
    "class MoodValSet(Dataset):\n",
    "    def __init__(self, load_abnormal=True, load_normal=True, loadASTrain=False, data_path='MOOD_val.h5', torchiosub=True, lazypatch=True, preload=False):\n",
    "        self.h5 = h5.File(data_path, 'r', swmr=True)\n",
    "        self.samples = []\n",
    "        if load_abnormal:\n",
    "            self.samples+=[(self.h5['abnormal'][i], self.h5['abnormal_mask'][i]) for i in list(self.h5['abnormal'])]\n",
    "        if load_normal:\n",
    "            self.samples+=[self.h5['normal'][i] for i in list(self.h5['normal'])]\n",
    "        if preload:\n",
    "            print('Preloading MoodValSet')\n",
    "            for i in range(len(self.samples)):\n",
    "                if len(self.samples[i]) == 2:\n",
    "                    self.samples[i] = (self.samples[i][0][:], self.samples[i][1][:])\n",
    "                else:\n",
    "                    self.samples[i] = self.samples[i][:]\n",
    "        self.loadASTrain = loadASTrain\n",
    "        self.torchiosub = torchiosub\n",
    "        self.lazypatch = lazypatch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.loadASTrain:\n",
    "            if self.torchiosub:\n",
    "                return Subject({'img':H5DSImage(self.samples[item][0], lazypatch=self.lazypatch)})\n",
    "            else:\n",
    "                return torch.from_numpy(self.samples[item][0][()]).unsqueeze(0)\n",
    "        else:\n",
    "            if self.torchiosub:\n",
    "                if len(self.samples[item]) == 2:\n",
    "                    return Subject({'img':H5DSImage(self.samples[item][0], lazypatch=self.lazypatch),\n",
    "                                    'gt':H5DSImage(self.samples[item][1], lazypatch=self.lazypatch)})\n",
    "                else:\n",
    "                    return Subject({'img':H5DSImage(self.samples[item], lazypatch=self.lazypatch),\n",
    "                                    'gt':H5DSImage(self.samples[item], lazypatch=self.lazypatch)}) #this is dirty. TODO\n",
    "\n",
    "            else:\n",
    "                return (torch.from_numpy(self.samples[item][0][()]).unsqueeze(0), torch.from_numpy(self.samples[item][1][()]).unsqueeze(0))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
